## 斐波那契堆

斐波那契堆拥有一个根链表，它是循环链表，其中的每一个节点都可以视为一棵斐波那契树，这样的结构使得合并操作的代价变得非常小。

### 插入 （insert）

插入节点只需要向根链表中插入节点即可，但过多的插入会使得根链表变得庞大，会使得斐波那契堆趋向于链表发展。

### 提取最小值（extract_min）

斐波那契堆始终维护着最小值的节点，所以在根链表中删除即可，代价很低。但是上面提到过多的插入会使得根链表过于庞大，在根链表中寻找下一个最小节点的代价可能就变得高昂。所以

    1. 将min的子节点的链表插入到根链表中(合并链表的代价也是常数操作)
    2. 合并根链表中具有相同度数(_degree)的节点，使得每一个节点的度数均不相同
    3. 根据书本Dn的推断可得，现在根链表中的节点至多为k=ceil(log2(n))，其中n是总的节点数目

### 合并度数相同的节点(consolidate)

由于n个节点分配成数目不等的子集，最多会k(见上)个子节点，所以辅助空间arr的size也为k，对于ptr=arr[m]而言，其表示ptr指涉的节点的度为m，当我们遍历根链表，若当前节点的度为c,且arr[c]不为空，那么就表示有两个节点的度数相同，就需要合并，将关键字大的链接到关键字小的节点上，直到所有节点的度数均不同。

    1. 对于节点x，若n=x.degree,且y=arr[n],y!=nullptr,那么就需要和y合并
    2. 如果x.key<y.key,那么y成为x的孩子，反之x就是y的孩子

### 减小节点的关键字(decrease_key)

初始不太明白为什么会有减小关键字的操作，而却1.没有增大关键字的操作，或者2.为什么会有个减小关键字的操作。但减小关键值的操作可能是为了删除节点而服务的。当减小了关键字的时候，如果仍能保持斐波那契堆的性质(父节点<子节点)，则可以不需要进行额外处理。否则

    1.剪切
    2.进行次级剪切


### 剪切(cut)

将节点作为子树剪切到根链表中，并将其父节点标识为已剪切(marked=truy，如果父节点存在)

### 次级剪切(cascading_cut)

实际上就是对于已标记为marked的节点，都剪切到根链表中

    1.如果父节点不存在，就什么也不需要做(当然，它已经在根链表中了呀)
    2.当前节点marked=false，则当前节点marked=true;
    3.否则就1.剪切，2.级联剪切

### 删除节点

函数本身并不难理解

    1.将节点的关键字替换成最小关键字
    2.抽取最小节点

但有很多奇怪的设定

    1.其他的接口几乎都没有返回一个节点x，而删除操作是面向用户的，但用户如何获得一个内部不开放的节点？
    2.该函数需要设置一个"无限小"的key值，但这似乎是概念上的，而斐波那契堆对于key_type的要求仅仅是其是可比较的，这对key_type做了更多的限制。对于自定义的可比较，我是否还得定义一个所谓的最小值？


### 后记

有一些疑惑仍然在我脑海，我有一些猜测，但我的知识储备不足以让我证明这些猜想。譬如说consolidate,cut和cascading_cut。这些操作都像是为了保证树的平衡性，以至于不会变成一个循环根链表或者链表形式的斐波那契树，但我很难证明。关于删除操作的奇怪设定，也可能是因为在斐波那契堆中使用搜索是低效的操作，而如何高效的返回关键字所对应的指针，则是留给实现者考虑的一环，或者可以进一步收缩key_type的限制，使其不可重复，然后搭配哈希表进行高效搜索。但无论如何，总是牺牲了一些东西。对于删除操作，我听见这函数似乎在说,给我一个要删除的节点，和一个最小的关键字，我就能高效的删除节点并保证树的平衡。至于如何拿到这两个，嘿，兄弟，交给你了。恰逢我也是个懒人，就丢给了它std::numeric_limit\<K>::min()，至于节点，就交给调用者吧。

什么？调用者也是我自己！